---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-config
data:
  config.yaml: |
    model_list:
      - model_name: deepseek-r1:1.5b
        litellm_params:
          model: ollama_chat/deepseek-r1:1.5b
          api_base: "http://ollama.ollama.svc.cluster.local:11434"
      - model_name: deepseek-r1:7b
        litellm_params:
          model: ollama_chat/deepseek-r1:7b
          api_base: "http://ollama.ollama.svc.cluster.local:11434"
      - model_name: llama3.2:3b
        litellm_params:
          model: ollama_chat/llama3.2:3b
          api_base: "http://ollama.ollama.svc.cluster.local:11434"
      - model_name: github_copilot/gpt-5
        litellm_params:
          model: github_copilot/gpt-5
          extra_headers: {"Editor-Version": "vscode/1.85.1", "Copilot-Integration-Id": "vscode-chat"}
      - model_name: github_copilot/gpt-5-mini
        litellm_params:
          model: github_copilot/gpt-5-mini
          extra_headers: {"Editor-Version": "vscode/1.85.1", "Copilot-Integration-Id": "vscode-chat"}
      - model_name: github_copilot/claude-sonnet-4
        litellm_params:
          model: github_copilot/claude-sonnet-4
          extra_headers: {"Editor-Version": "vscode/1.85.1", "Copilot-Integration-Id": "vscode-chat"}

    general_settings:
      database_connection_pool_limit: 10 # limit the number of database connections to = MAX Number of DB Connections/Number of instances of litellm proxy (Around 10-20 is good number)

      # OPTIONAL Best Practices
      disable_spend_logs: False # turn off writing each transaction to the db. We recommend doing this is you don't need to see Usage on the LiteLLM UI and are tracking metrics via Prometheus
      allow_requests_on_db_unavailable: True # Only USE when running LiteLLM on your VPC. Allow requests to still be processed even if the DB is unavailable. We recommend doing this if you're running LiteLLM on VPC that cannot be accessed from the public internet.

    litellm_settings:
      request_timeout: 600    # raise Timeout error if call takes longer than 600 seconds. Default value is 6000seconds if not set
      set_verbose: False      # Switch off Debug Logging, ensure your logs do not have any debugging on
      json_logs: true         # Get debug logs in json format
      cache: True

    router_settings:
      routing_strategy: usage-based-routing-v2
      redis_host: os.environ/REDIS_HOST
      redis_port: os.environ/REDIS_PORT
      redis_password: os.environ/REDIS_PASSWORD

    litellm_settings:
      cache: True
      cache_params:
        type: redis
        host: os.environ/REDIS_HOST
        port: os.environ/REDIS_PORT
        password: os.environ/REDIS_PASSWORD
